{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8194438,"sourceType":"datasetVersion","datasetId":4852897}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport pandas as pd\nimport os.path\n\nclass Loader(Dataset):\n    def __init__(self, input, output):\n        \"\"\"\n        input = pandas dataframe\n        output = pandas dataframe\n        After transform to tensor, should have dimensions\n            input.shape == [N, input_dim]\n            output.shape == [N]\n        \"\"\"\n        self.input = torch.tensor(input.values)\n        self.input_dim = self.input.shape[1] \n        self.output = torch.tensor(output.values)\n    \n    def __len__(self):\n        return self.output.shape[0]\n\n    def __getitem__(self, index):\n        return self.input[index], self.output[index]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T12:09:35.558300Z","iopub.execute_input":"2024-04-23T12:09:35.558897Z","iopub.status.idle":"2024-04-23T12:09:40.605431Z","shell.execute_reply.started":"2024-04-23T12:09:35.558863Z","shell.execute_reply":"2024-04-23T12:09:40.604452Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport os.path\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom .model import SVM, HingeLoss\nfrom dataloader import Loader\ndef process_dataset(csv_file, input_cols, output_col, cat_one, cat_two):\n    df = pd.read_csv(csv_file)\n    # Filter columns on input and output columns only.\n    df = df.filter(items = input_cols + [output_col])\n    # Change category into 1 and -1\n    df = df.loc[df[output_col].isin([cat_one, cat_two])]\n    df[output_col+'Label'] = df[output_col].apply(lambda s: 1 if s == cat_one else -1)\n    df = df.drop(output_col, axis=1)\n    return df\ndef visualize_separator(model, df):\n    model.eval()\n    linear = model.linear\n    w, b = linear.weight.data.flatten(), linear.bias.data\n    w1, w2 = w\n    # Draw the line determined by weight and bias.\n    # Since w must be a nonzero vector, the point -bw/(|w|^2) must on the line.\n    # The above point is also nearest to the origin from the line. \n    P1 = - b * w / (w1**2 + w2**2)\n    P2 = P1 + torch.tensor([-w2, w1])\n    plt.axline((P1[0], P1[1]), (P2[0], P2[1]))\n\n    x1 = list(df[input_cols[0]])\n    x2 = list(df[input_cols[1]])\n    y = list(df[output_col+'Label'])\n    color = ['g' if item == 1 else 'r' for item in y]\n    plt.scatter(x1, x2, c=color)\n    plt.xlim(min(x1)-0.1, max(x1)+0.1)\n    plt.ylim(min(x2)-0.1, max(x2)+0.1)\n    plt.xlabel(\"x1\")\n    plt.ylabel(\"x2\")\n    plt.show()\n\nif __name__ == '__main__':\n    # Input here\n    inputs = [[5.1, 1.3], [4.6, 1.0], [6.0, 4.0]]\n    input_dim = 2\n    model_path = 'SVMmodel1.pth'\n    draw_svm = True\n    # Below 5 lines should be the same from train.py\n    csv_file = \"Iris.csv\"\n    input_cols = ['SepalLengthCm', 'PetalLengthCm']\n    output_col = 'Species'\n    cat_one = 'Iris-setosa'  # Will be labelled 1\n    cat_two = 'Iris-versicolor' # Will be labelled -1\n\n    # Pre-process dataset\n    df = process_dataset(csv_file, input_cols, output_col, cat_one, cat_two)\n    model = SVM(input_dim)\n    model.load_state_dict(torch.load(model_path))\n    model.eval()\n    print(f\"Weight is {model.linear.weight.data}.\")\n    print(f\"Bias is {model.linear.bias.data}.\")\n    print(f\"The SVM straight line equation is \", )\n    print(\"+\".join([\"(\"+str(round(model.linear.weight.data[0][i-1].item(),4))+\")\"+f\"x{i}\" for i in range(1, input_dim+1)]) + f\"+({round(model.linear.bias.data.item(),4)})=0\")\n    # Use below to visualize Support Vector Machine if input_dim == 2\n    if input_dim == 2 and draw_svm:\n        visualize_separator(model, df)\n\n    # Inference about input \n    input_tensor = torch.tensor(inputs).float()\n    output = model(input_tensor)\n    output = 2*(output >= 0).float()-1\n    print(f\"{len(inputs)} input(s) received.\")\n    for ind, input in enumerate(inputs):\n        collect = [f\"{input_cols[i]}: {input[i]}\" for i in range(input_dim)]\n        s = \", \".join(collect)\n        pred = cat_one if output[ind] == 1 else cat_two\n        s += f\" => Prediction: {pred}.\"\n        s = f\"{ind+1}) \" + s\n        print(s)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T12:34:54.017619Z","iopub.execute_input":"2024-04-23T12:34:54.018081Z","iopub.status.idle":"2024-04-23T12:34:54.084371Z","shell.execute_reply.started":"2024-04-23T12:34:54.018042Z","shell.execute_reply":"2024-04-23T12:34:54.082884Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVM, HingeLoss\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Loader\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_dataset\u001b[39m(csv_file, input_cols, output_col, cat_one, cat_two):\n","\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"],"ename":"ImportError","evalue":"attempted relative import with no known parent package","output_type":"error"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nclass SVM(nn.Module):\n    def __init__(self, input_dim):\n        super(SVM, self).__init__()\n        self.input_dim = input_dim\n        self.linear = nn.Linear(input_dim, 1)\n        \n    def forward(self, input):\n        # Expect input to be shape (N, self.input_dim)\n        output = self.linear(input) # Shape (N, 1)\n        output = output.flatten() # Shape (N)\n        return output \n\ndef HingeLoss(pred, truth):\n    # Expect both of shape (N)\n    loss_tensor = nn.ReLU()(1-pred*truth)\n    return torch.mean(loss_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T12:09:40.899694Z","iopub.status.idle":"2024-04-23T12:09:40.900258Z","shell.execute_reply.started":"2024-04-23T12:09:40.900078Z","shell.execute_reply":"2024-04-23T12:09:40.900095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, random_split\nfrom sklearn.model_selection import train_test_split\nimport os.path\nimport pandas as pd\nimport torch.optim as optim\n\nfrom .model import SVM, HingeLoss\nfrom dataloader import Loader\n\n################################################\n\n# Input necessary data here\ncsv_file = \"Iris.csv\"\ninput_cols = ['SepalLengthCm', 'PetalLengthCm']\noutput_col = 'Species'\ncat_one = 'Iris-setosa'  # Will be labelled 1\ncat_two = 'Iris-versicolor' # Will be labelled -1\ntrain_ratio = 0.8\n\nepochs = 100\nbatch_size = 8\nlearning_rate = 0.05\nweight_decay = 1e-3\nvisualize_data = False # Visualize only if input_cols has two entries\nmodel_path = \"SVMmodel1.pth\"\n\n################################################\n# Preparing data\ninput_dim = len(input_cols)\nprint(\"Preparing data...\")\nif not os.path.isfile(csv_file):\n    print(\"Couldn't find {}. Exit.\".format(csv_file))\n    exit()\ndf = pd.read_csv(csv_file)\n# Filter columns on input and output columns only.\ndf = df.filter(items = input_cols + [output_col])\n# Change category into 1 and -1\ndf = df.loc[df[output_col].isin([cat_one, cat_two])]\ndf[output_col+'Label'] = df[output_col].apply(lambda s: 1 if s == cat_one else -1)\ninput_train, input_val, output_train, output_val = train_test_split(df[input_cols], \n                                                df[output_col+'Label'], train_size=train_ratio, \n                                                stratify=df[output_col+'Label'])\ntrain_dataset = Loader(input_train, output_train)\nval_dataset = Loader(input_val, output_val)\nprint(f\"Train dataset has {len(train_dataset)} entries.\\nValidating dataset has {len(val_dataset)} entries.\")\n# Dump into Dataloader\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n################################################\n\n# Visualize the data if input dimension is 2\nif len(input_cols) == 2 and visualize_data:\n    print(\"Visualizing data...\")\n    import matplotlib.pyplot as plt\n    x1 = list(df[input_cols[0]])\n    x2 = list(df[input_cols[1]])\n    y = list(df[output_col+'Label'])\n    color = ['g' if item == 1 else 'r' for item in y]\n    plt.scatter(x1, x2, c=color)\n    plt.show()\n\n################################################\n# Training\nmodel = SVM(input_dim=input_dim)\ncriterion = HingeLoss\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\nfor epoch in range(epochs):  # loop over the dataset multiple times\n    print(\"=\"*50)\n    running_loss = 0.0\n    train_loader_n = len(train_loader)\n    for i, data in enumerate(train_loader, 0):\n        model.train()\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs.float())\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        # print(f\"Epoch {epoch+1} step {i+1}/{train_loader_n}, loss is {round(loss.item(), 2)}.\")\n        running_loss += loss.item()\n    print(f\"Epoch {epoch+1} loss is {round(running_loss/train_loader_n, 4)}.\")\n\n    eval_rloss = 0\n    val_loader_n = len(val_loader)\n    for i, data in enumerate(val_loader, 0):\n        model.eval()\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # forward + backward + optimize\n        outputs = model(inputs.float())\n        loss = criterion(outputs, labels)\n\n        # print statistics\n        # print(f\"Epoch {epoch+1} step {i+1}/{train_loader_n}, loss is {round(loss.item(), 2)}.\")\n        eval_rloss += loss.item()\n    print(f\"Epoch {epoch+1} eval loss is {round(eval_rloss/val_loader_n, 4)}.\")\n\nprint('Finished Training')\nprint('Model parameters are')\nprint(model.linear.weight.data)\nprint(model.linear.bias.data)\ntorch.save(model.state_dict(), model_path)\nprint(f\"Model saved in {model_path}.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T12:09:40.901490Z","iopub.status.idle":"2024-04-23T12:09:40.902052Z","shell.execute_reply.started":"2024-04-23T12:09:40.901871Z","shell.execute_reply":"2024-04-23T12:09:40.901888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}